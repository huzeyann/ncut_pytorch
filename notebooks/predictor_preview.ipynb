{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "using_colab = False",
   "id": "3faa895f62316df0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install ncut-pytorch[vision]\n",
    "    !{sys.executable} -m pip install matplotlib ipympl widgetsnbextension\n",
    "\n",
    "    !mkdir images\n",
    "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/truck.jpg\n",
    "    !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/groceries.jpg\n",
    "\n",
    "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ],
   "id": "eb9059bd4b1ca841",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "from ncut_pytorch.predictor import NcutDinoPredictorSR, NcutDinoPredictor\n",
    "from PIL import Image\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "input_size = 512  # or 1024, 256\n",
    "if is_cuda:\n",
    "    predictor = NcutDinoPredictorSR(input_size=input_size, dtype=torch.float16, batch_size=8)\n",
    "    predictor = predictor.to('cuda')\n",
    "else:\n",
    "    predictor = NcutDinoPredictor(input_size=input_size, dtype=torch.float32, batch_size=8)\n",
    "    predictor = predictor.to('cpu')"
   ],
   "id": "8593f2e64fabf7d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "default_images = ['./images/view_0.jpg', './images/view_1.jpg', './images/view_2.jpg',\n",
    "                  './images/view_3.jpg', './images/view_ego.jpg', './images/image2.jpg']\n",
    "\n",
    "images = [Image.open(image_path) for image_path in default_images]\n",
    "predictor.set_images(images)"
   ],
   "id": "5156c9dfd2be6482",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%matplotlib widget",
   "id": "fd6c4f1ad230273c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "masks = predictor.preview([300, 579], 0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def blend_mask(img, mask, alpha=0.8):\n",
    "    mask = mask.resize((img.width, img.height), resample=Image.Resampling.NEAREST)\n",
    "    img = np.array(img).astype(np.float32)\n",
    "    mask = np.array(mask).astype(np.float32)\n",
    "    blend = img * (1 - alpha) + mask * alpha\n",
    "    h, w = blend.shape[:2]\n",
    "    blend = blend.reshape(h*w, 3)\n",
    "    mask = mask.reshape(h*w, 3)\n",
    "    img = img.reshape(h*w, 3)\n",
    "    blend[mask[:, 0] == 255] = img[mask[:, 0] == 255]\n",
    "    blend = blend.reshape(h, w, 3)\n",
    "    blend = blend.astype(np.uint8)\n",
    "    return Image.fromarray(blend)\n",
    "\n",
    "def plot_masks(images, masks, fig, axes):\n",
    "    color_values = np.array([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    color_values = plt.get_cmap('plasma_r')(color_values)\n",
    "    color_values = (color_values * 255).astype(np.uint8)\n",
    "\n",
    "    for idx, (ax, img) in enumerate(zip(axes, images)):\n",
    "        ax.clear()\n",
    "        mask = np.ones((*masks[0][0].shape, 3)) * 255\n",
    "        mask = mask.astype(np.uint8)\n",
    "        for i in range(len(color_values)):\n",
    "            mask[masks[i][idx]] = color_values[i][:3]\n",
    "        mask_img = Image.fromarray(mask)\n",
    "        ax.imshow(blend_mask(img, mask_img, alpha=0.8))\n",
    "        ax.set_axis_off()\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 5))\n",
    "axes = axes.flatten()\n",
    "plot_masks(images, masks, fig, axes)\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes is None or event.xdata is None or event.ydata is None:\n",
    "        return\n",
    "    for idx, ax in enumerate(axes):\n",
    "        if ax == event.inaxes:\n",
    "            x, y = event.xdata, event.ydata\n",
    "            # Recompute masks for all images, using the hovered coordinates and image index\n",
    "            masks_new = predictor.preview([x, y], idx)\n",
    "            plot_masks(images, masks_new, fig, axes)\n",
    "            break\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "plt.show()"
   ],
   "id": "dd14a6482fb26868",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
